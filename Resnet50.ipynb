{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet50.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_YIYWb4h7y_",
        "outputId": "e1b9530f-e479-4a36-fccc-161cfcf96f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp \"/content/drive/MyDrive/垃圾分類/sample.zip\" /content/"
      ],
      "metadata": {
        "id": "B3Dr2aONh_ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjOkCn4DDu6w"
      },
      "outputs": [],
      "source": [
        "! unzip /content/sample.zip > data_unzip.log"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from keras.applications.resnet import ResNet50\n",
        "#from tensorflow.python.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "#from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "def save_model(model, save_name=\"mymodel\"):\n",
        "    \"\"\"\n",
        "    model : Keras Model class\n",
        "    save_name : str\n",
        "    \"\"\"\n",
        "    # 儲存模型-tf格式\n",
        "    # Convert the model.\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    tflite_model = converter.convert()\n",
        "    # Save the model.\n",
        "    with open(\"./\" + save_name + \".tflite\", 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "    # 儲存模型-keras格式\n",
        "    model.save(\"./\" + save_name + \".h5\")\n",
        "\n",
        "# 資料路徑\n",
        "DATASET_PATH  = 'sample'\n",
        "\n",
        "# 影像大小\n",
        "IMAGE_SIZE = (224, 224)\n",
        "\n",
        "# 影像類別數\n",
        "NUM_CLASSES = 6\n",
        "\n",
        "# 若 GPU 記憶體不足，可調降 batch size 或凍結更多層網路\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "# 凍結網路層數\n",
        "FREEZE_LAYERS = 2\n",
        "\n",
        "# Epoch 數\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# 模型輸出儲存的檔案\n",
        "WEIGHTS_FINAL = 'model-resnet50-final.h5'\n",
        "\n",
        "# 透過 data augmentation 產生訓練與驗證用的影像資料\n",
        "train_datagen = ImageDataGenerator(rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   channel_shift_range=10,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "train_batches = train_datagen.flow_from_directory(DATASET_PATH + '/train',\n",
        "                                                  target_size=IMAGE_SIZE,\n",
        "                                                  interpolation='bicubic',\n",
        "                                                  class_mode='categorical',\n",
        "                                                  shuffle=True,\n",
        "                                                  batch_size=BATCH_SIZE)\n",
        "\n",
        "valid_datagen = ImageDataGenerator()\n",
        "valid_batches = valid_datagen.flow_from_directory(DATASET_PATH + '/valid',\n",
        "                                                  target_size=IMAGE_SIZE,\n",
        "                                                  interpolation='bicubic',\n",
        "                                                  class_mode='categorical',\n",
        "                                                  shuffle=False,\n",
        "                                                  batch_size=BATCH_SIZE)\n",
        "\n",
        "# 輸出各類別的索引值\n",
        "for cls, idx in train_batches.class_indices.items():\n",
        "    print('Class #{} = {}'.format(idx, cls))\n",
        "\n",
        "# 以訓練好的 ResNet50 為基礎來建立模型，\n",
        "# 捨棄 ResNet50 頂層的 fully connected layers\n",
        "net = ResNet50(include_top=False, weights='imagenet', input_tensor=None,\n",
        "               input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3))\n",
        "x = net.output\n",
        "x = Flatten()(x)\n",
        "\n",
        "# 增加 DropOut layer\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# 增加 Dense layer，以 softmax 產生個類別的機率值\n",
        "output_layer = Dense(NUM_CLASSES, activation='softmax', name='softmax')(x)\n",
        "\n",
        "# 設定凍結與要進行訓練的網路層\n",
        "net_final = Model(inputs=net.input, outputs=output_layer)\n",
        "for layer in net_final.layers[:FREEZE_LAYERS]:\n",
        "    layer.trainable = False\n",
        "for layer in net_final.layers[FREEZE_LAYERS:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# 使用 Adam optimizer，以較低的 learning rate 進行 fine-tuning\n",
        "net_final.compile(optimizer=Adam(lr=1e-5),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 輸出整個網路結構\n",
        "print(net_final.summary())\n",
        "\n",
        "# 訓練模型\n",
        "train_model=net_final.fit_generator(train_batches,\n",
        "                        steps_per_epoch = train_batches.samples // BATCH_SIZE,\n",
        "                        validation_data = valid_batches,\n",
        "                        validation_steps = valid_batches.samples // BATCH_SIZE,\n",
        "                        epochs = NUM_EPOCHS)\n",
        "\n",
        "# 儲存訓練好的模型\n",
        "net_final.save(WEIGHTS_FINAL)\n",
        "\n",
        "acc = train_model.history['accuracy']\n",
        "val_acc = train_model.history['val_accuracy']\n",
        "\n",
        "loss = train_model.history['loss']\n",
        "val_loss = train_model.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "test_loss, test_acc = net_final.evaluate_generator(valid_batches,\n",
        "                            steps=valid_batches.samples//BATCH_SIZE,\n",
        "                            verbose=1)\n",
        "print('test acc:', test_acc)\n",
        "print('test loss:', test_loss)"
      ],
      "metadata": {
        "id": "UscCRzLwFtkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "#Confution Matrix and Classification Report\n",
        "Y_pred = net_final.predict_generator(valid_batches, valid_batches.samples // BATCH_SIZE+1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(valid_batches.classes, y_pred))\n",
        "print('Classification Report')\n",
        "target_names = ['battery', 'clothes', 'metal', 'paper', 'plastic', 'white-glass']\n",
        "print(classification_report(valid_batches.classes, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "id": "FniTDHfBBfpp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}